\documentclass[a4paper, 12pt]{article}
\usepackage[utf8]{inputenc}
\usepackage{polski}
\usepackage{hyperref}
\usepackage{graphicx}
\usepackage{indentfirst}
\usepackage{float}
\usepackage{amsfonts}

\title{Metody odkrywania wiedzy -- wykrywanie ataków sieciowych}
\author{Adam Stelmaszczyk\\ Anna Stępień}

\begin{document}

\maketitle

\tableofcontents

\newpage

\section{Interpretacja tematu projektu}
Projekt ma na celu analizę działania różnych algorytmów klasyfikacji zastosowanych
w procesie wykrywania ataków sieciowych. Połączenia sieciowe można zaklasyfikować do jednej
z pięciu klas:
\begin{itemize}
  \item normal -- połączenia prawidłowe,
  \item probe -- odpytywanie, np. skanowanie portów,
  \item dos -- ataki typu Denial of Service,
  \item u2r -- ataki typu User to Root, polegające na przejęciu praw administratora, 
np. ataki przepełnienia bufora,
  \item r2l -- ataki typu Remote to Local, polegające na nieautoryzowanym dostępie ze zdalnego komputera.
\end{itemize} 

\section{Opis wykorzystanych algorytmów}\label{algorithms}

\subsection{k-NN}
k-NN jest algorytmem, który dokonuje klasyfikacji na podstawie podobieństwa do k 
najbardziej podobnych przykładów ze zbioru uczącego. W~celu oszacowania podobieństwa 
poszczególnych próbek, stosowane są miary odległości takie jak np. metryka euklidesowa lub Manhattan. 
Klasa, która przypisywana jest do badanego obiektu ustalana jest na podstawie klasy 
reprezentowanej przez największą spośród wybranych wcześniej k przykładów.

Algorytm k-NN zostanie przetestowany z~wykorzystaniem funkcji 
\texttt{knn} oferowanej przez pakiet \texttt{FNN} języka~R 
\footnote{\url{http://cran.r-project.org/web/packages/FNN/}}.

\subsection{Naiwny klasyfikator Bayesa}

Klasyfikator Bayesa wybiera klasę, która jest najbardziej prawdopodna dla danego przykładu na 
podstawie prawdopodobieństwa
warunkowego $P(c \mid x)$, gdzie $c$ oznacza etykietę klasy, a $x$ jest przykładem. 
Jest to tzw. prawdopodobieństwo
\textit{a posteriori}. Wyznaczane jest ze wzoru:

$$ P(c \mid x) = \frac{P(x \mid c)P(c)}{P(x)} $$

Przy poszukiwaniu maksimum $P(c \mid x)$ mianownik $P(x)$ można pominąć bez zmiany wyniku 
maksymalizacji.
Prawdopodobieństwo \textit{a posteriori} $P(c)$ można oszacować na podstawie częstości 
występowania klas w zbiorze treningowym.
Natomiast prawdopodobieństwo $P(x \mid c)$ jest szacowane ze wzoru:

$$ P(x \mid c) = \prod_{i=1}^n P(a_i(x) \mid c)$$

gdzie $a_i(x)$ oznacza $i$-ty atrybut przykładu $x$.
Przyjęte zostało założenie, że wartości poszczególnych atrybutów są niezależne od siebie.
Na tym polega ,,naiwność'' klasyfikatora Bayesa.

Naiwny klasyfikator Bayesa zostanie przetestowany przy pomocy funkcji \texttt{naiveBayes} z~pakietu \texttt{e1071} języka~R
\footnote{\url{http://www-users.cs.york.ac.uk/~jc/teaching/arin/R_practical/}}.

\subsection{SVM}
SVM jest klasyfikatorem binarnym, który ma na celu wyznaczenie hiperpłaszczyzny rozdzielającej 
z~maksymalnym marginesem przykłady należące do dwóch klas. W~ramach projektu realizowana będzie 
klasyfikacja mająca na celu przypisanie połączeń sieciowych do jednej z~pięciu klas. 
Problem klasyfikacji wieloklasowej może być zdekomponowany do szeregu problemów klasyfikacji binarnej. 
W~projekcie wykorzystane zostanie podejście \textit{one-against-one}, 
które polega na zbudowaniu klasyfikatora SVM dla każdej pary klas. 

Do przetestowania klasyfikatora SVM zostanie wykorzystana funkcja \texttt{svm} z~pakietu 
\texttt{e1071} języka~R \footnote{\url{http://cran.r-project.org/web/packages/e1071/}}.

\section{Przygotowanie danych}

Podczas realizacji projektu został wykorzystany zbiór danych z konkursu 
KDD'99 Classifier Learning Contest
\footnote{\url{www.sigkdd.org/kdd-cup-1999-computer-network-intrusion-detection}}.
Każdy przykład zawiera 41 atrybutów połączenia sieciowego. W poniższej tabeli przedstawiono
szczegóły wszystkich atrybutów.
42 kolumna danych treningowych zawiera typ ataku, który bezpośrednio mapuję się na
jedną z 5 ostatecznych klas. \\

\begin{tabular}{ | l | p{3cm} | p{3cm} | p{6cm} | } \hline
Nr & Nazwa & Opis & Zbiór wartości \\ \hline
1*      & duration & czas połączenia w sekundach & $\mathbb Z_{\ge 0}$ \\ \hline
2*      & protocol\_type & rodzaj protokołu & icmp, tcp, udp \\ \hline
3*      & service & usługa na serwerze & smtp, bgp, imap4, courier, name, exec, ftp, echo, http\_2784,
                       http\_443, discard, kshell, login, http, Z39\_50, vmnet, supdup,
                       gopher, printer, aol, tftp\_u, csnet\_ns, http\_8001, eco\_i, time,
                       ssh, efs, hostnames, X11, klogin, sql\_net, ldap, private,
                       auth, uucp, pm\_dump, link, ctf, IRC, ecr\_i, netbios\_ns, urp\_i,
                       pop\_2, pop\_3, rje, systat, ftp\_data,finger, tim\_i, remote\_job,
                       other, domain\_u, urh\_i, iso\_tsap, netstat, daytime, whois, shell,
                       mtp, sunrpc, uucp\_path, red\_i, harvest, nnsp, telnet, domain,
                       ntp\_u, netbios\_dgm, nntp, netbios\_ssn \\ \hline
4      & flag & status połączenia & REJ, SF, SH, RSTO, OTH, RSTR, RSTOS0, S0, S1, S2, S3 \\ \hline
5*      & src\_bytes  & bajty przesłane w połączeniu & $\mathbb Z_{\ge 0}$ \\ \hline
6*      & dst\_bytes  & bajty pobrane w połączeniu  & $\mathbb Z_{\ge 0}$ \\ \hline
7      & land & 1, jeśli źródło oraz cel połączenia ma tego samego hosta i port & 0, 1 \\ \hline
8      & wrong\_fragment  & liczba pakietów oznaczonych jako ,,wrong'' & $\mathbb Z_{\ge 0}$ \\ \hline
9      & urgent  & liczba pakietów oznaczonych jako ,,urgent''  & $\mathbb Z_{\ge 0}$ \\ \hline
\end{tabular}

\begin{tabular}{ | l | l | p{6cm} | p{2,1cm} | } \hline
Nr & Nazwa & Opis & Zbiór wartości \\ \hline
10      & hot & liczba wskaźników ,,hot'' dla akcji, np. uruchamianie programów & $\mathbb Z_{\ge 0}$ \\ \hline
11      & num\_failed\_logins  & liczba nieudanych prób logowania w połączeniu & $\mathbb Z_{\ge 0}$ \\ \hline
12*      & logged\_in  & 1, jeśli udało się zalogować &  0, 1 \\ \hline
13      & num\_compromised & liczba wystąpień błędu ,,not found'' podczas połączenia &  $\mathbb Z_{\ge 0}$ \\ \hline
14      & root\_shell  & 1, jeśli uzyskano konsolę z uprawnieniami root  &  0, 1 \\ \hline
15      & su\_attempted  & 1, jeśli użyto komendy \texttt{su} &  0, 1 \\ \hline
16      & num\_root  & liczba operacji wykonanych jako root  & $\mathbb Z_{\ge 0}$ \\ \hline
17      & num\_file\_creations  & liczba utworzonych plików  & $\mathbb Z_{\ge 0}$ \\ \hline
18      & num\_shells  & liczba zalogowań jako normalny użytkownik & $\mathbb Z_{\ge 0}$ \\ \hline
19      & num\_access\_files  & liczba operacji na plikach kontroli dostępu & $\mathbb Z_{\ge 0}$ \\ \hline
20      & num\_outbound\_cmds & liczba poleceń wychodzących w sesji FTP & $\mathbb Z_{\ge 0}$ \\ \hline
21      & is\_hot\_login  & 1, jeśli login należy to listy ,,hot'', tzn. jeśli login to root albo adm &  0, 1 \\ \hline
22      & is\_guest\_login  & 1, jeśli login należy to listy ,,guest'' &  0, 1 \\ \hline
23*     & count & liczba połączeń do tego samego hosta w przęciągu 2 sekund & $\mathbb Z_{\ge 0}$ \\ \hline
24*      & srv\_count   & liczba połączeń z tą samą usługą w przeciągu 2 sekund &  $\mathbb Z_{\ge 0}$ \\ \hline
25      & serror\_rate        & \% połączeń o tym samym hoście z błędami SYN  & $\mathbb{R} \in [0; 1]$ \\ \hline
26      & srv\_serror\_rate   & \% połączeń do tej samej usługi z błędami SYN & $\mathbb{R} \in [0; 1]$ \\ \hline
27      & rerror\_rate        & \% połączeń o tym samym hoście z błędami REJ   & $\mathbb{R} \in [0; 1]$ \\ \hline
28      & srv\_rerror\_rate   & \% połączeń do tej samej usługi z błędami REJ  & $\mathbb{R} \in [0; 1]$ \\ \hline
29*      & same\_srv\_rate     & \% połączeń do tej samej usługi  &  $\mathbb{R} \in [0; 1]$ \\ \hline
30      & diff\_srv\_rate     & \% połączeń do różnych usług &  $\mathbb{R} \in [0; 1]$ \\ \hline  
31*      & srv\_diff\_host\_rate   & \% połączeń do różnych hostów   & $\mathbb{R} \in [0; 1]$ \\ \hline
\end{tabular}

\begin{tabular}{ | l | l | p{5cm} | p{1,9cm} | } \hline
Nr & Nazwa & Opis & Zbiór wartości \\ \hline
32      & dst\_host\_count & liczba połączeń do tego samego adresu IP  &  $\mathbb Z_{\ge 0}$ \\ \hline
33      & dst\_host\_srv\_count  & liczba połączeń do tego samego portu docelowego   & $\mathbb Z_{\ge 0}$ \\ \hline
34      & dst\_host\_same\_srv\_rate  & \% połączeń do tej samej usługi w stosunku do liczby połączeń do tego samego adresu IP (atrybut 31) & $\mathbb{R} \in [0; 1]$ \\ \hline
35*      & dst\_host\_diff\_srv\_rate  & \% połączeń do tej różnych usług w stosunku do liczby połączeń do tego samego adresu IP (atrybut 31) & $\mathbb{R} \in [0; 1]$ \\ \hline
36*      & dst\_host\_same\_src\_port\_rate & \% połączeń do tego samego portu źródłowego w stosunku do liczby połączeń do tego samego portu docelowego (atrybut 32)  & $\mathbb{R} \in [0; 1]$ \\ \hline
37*      & dst\_host\_srv\_diff\_host\_rate & \% połączeń do różnych portów źródłowych w stosunku do liczby połączeń do tego samego portu docelowego (atrybut 32)  &  $\mathbb{R} \in [0; 1]$ \\ \hline

38*      & dst\_host\_serror\_rate       & \% połączeń o tym samym hoście z błędami SYN w stosunku do atrybutu 31        &  $\mathbb{R} \in [0; 1]$ \\ \hline  
39      & dst\_host\_srv\_serror\_rate  & \% połączeń o tym samym hoście z błędami SYN w stosunku do atrybutu 32 & $\mathbb{R} \in [0; 1]$ \\ \hline

40      & dst\_host\_rerror\_rate        & \% połączeń o tym samym hoście z błędami REJ w stosunku do atrybutu 31 & $\mathbb{R} \in [0; 1]$ \\ \hline
41      & dst\_host\_srv\_rerror\_rate   & \% połączeń o tym samym hoście z błędami REJ w stosunku do atrybutu 32 & $\mathbb{R} \in [0; 1]$ \\ \hline
\end{tabular}

\begin{tabular}{ | l | l | p{4,5cm} | p{5,3cm} | } \hline
Nr & Nazwa & Opis & Zbiór wartości \\ \hline
42      & attack\_type & rodzaj ataku sieciowego & back, buffer\_overflow, ftp\_write, guess\_passwd, imap, ipsweep, land, loadmodule, multihop, neptune, nmap, normal, perl, phf, pod, portsweep, rootkit, satan, smurf, spy, teardrop, warezclient, warezmaster \\ \hline
\end{tabular} \\\\

Znakiem gwiazdki (*) oznaczono 14 atrybutów wybranych do klasyfikacji.
Sposób w jaki je wybrano opisano w rozdziale \ref{sec:selekcja}.

\section{Statystyczny opis danych}

Podczas testów wykorzystane zostały dwa zbiory treningowe -- pełny zbiór treningowy 
liczący 4898431 przykładów oraz jego losowy, 1-procentowy podzbiór.
W~tabeli \ref{table:100percent} został przedstawiony rozkład klas przykładów w~pełnym zbiorze
treningowym. 

\begin{table}[H]
\centering
\begin{tabular}{ | l | l | l | l | l | l | } \hline
	normal & probe & dos & u2r & r2l & razem \\  \hline
	972780 & 41102 & 3883370 & 52 & 1126 & 4898431 \\ \hline
	19.86\% & 0.84\% & 79.28\% & 0.001\% & 0.023\% & \\ \hline
\end{tabular}
\caption{Rozkład klas w pełnym zbiorze treningowym}
\label{table:100percent}
\end{table}

W~tabeli \ref{table:1percent} został przedstawiony rozkład klas przykładów w 
zbiorze treningowym będącym losowym, 1-procentowym
podzbiorem pełnego zbioru treningowego.
\begin{table}[H]
\centering
\begin{tabular}{ | l | l | l | l | l | l | } \hline
	normal & probe & dos & u2r & r2l & razem \\ \hline
	9725 & 414 & 38831 & 2 & 12 & 48984 \\ \hline
	19.85\%  & 0.85\%  & 79.27\% & 0.004\%  & 0.024\% &  \\ \hline
\end{tabular}
\caption{Rozkład klas w zbiorze treningowym będącym losowym, 1-procentowym
 podzbiorem pełnego zbioru treningowego}
\label{table:1percent}
\end{table}

W~tabeli \ref{table:test} został przedstawiony rozkład klas przykładów w zbiorze testowym.
\begin{table}[H]
\centering
	\begin{tabular}{ | l | l | l | l | l | l | } \hline
		normal & probe & dos & u2r & r2l & razem \\ \hline
		60592 & 4166 & 229853 & 228 & 16189 & 311028 \\ \hline
		19.48\% & 1.34\% & 73.9\% & 0.073\%  & 5.2\% & \\ \hline
	\end{tabular}
\caption{Rozkład klas w zbiorze testowym.}
\label{table:test}
\end{table}

Konkursowy zbiór testowy posiadał zupełnie inny empiryczny rozkład prawdopodobieństwa klas niż zbiór treningowy.
Największa różnica liczby przykładów wystąpiła dla klasy r2l. Zbiór trenujący posiada zaledwie
1126 przykładów tej klasy (0,023\% całości), natomiast zbiór testujący aż 16189 (5,2\% całego
zbioru testującego). Zbiór testujący posiada około 14 razy więcej przykładów r2l niż zbiór
trenujący, pomimo tego, że jest około 16 razy mniejszy od niego. Powoduje to, że klasa r2l
jest najtrudniej rozpoznawalna, co potwierdzają wyniki przedstawione w rozdziale \ref{sec:wyniki}.

\section{Transformacja danych}

Na początku dane zostały przejrzane w poszukiwaniu pojedynczych wartości odstających
powstałych np. na skutek błędu ludzkiego. Dokonano tego przy pomocy funkcji \texttt{summary}
języka R. Nie znaleziono wartości odstających. 
Następnie atrybuty wyliczeniowe zostały zamienione na liczbowe.

Wykorzystywane w~projekcie dane charakteryzują się nierównomiernym rozkładem klas. 
Dlatego przetestowano resampling przykładów treningowych, w~celu uzyskania równomiernego rozkładu klas. 
Wykorzystany został algorytm \texttt{SMOTE} udostępniany przez pakiet 
\texttt{DMwR} \footnote{\url{http://cran.r-project.org/web/packages/DMwR/}} języka~R.

\section{Selekcja atrybutów}
\label{sec:selekcja}

Wykorzystana została funkcja \texttt{importance} z pakietu lasów losowych
\footnote{\url{http://cran.r-project.org/web/packages/randomForest/randomForest.pdf}}.
Funkcja ta zwraca wartości dwóch miar ważności dla wszystkich atrybutów.
Pierwszą miarą jest średni spadek precyzji, drugą jest średni spadek nieczystości węzłów.

%TODO wykres i dane numeryczne

\section{Ocena jakości modeli}

Do porównywania jakości modeli wykorzystano błąd klasyfikacji na zbiorze testowym 
\texttt{corrected}\footnote{\url{http://www-cse.ucsd.edu/users/elkan/corrected.gz}},
przygotowanym przez autorów konkursu KDD'99.
Zbiór ten zawiera 311028 przykładów. 
Uczestnicy KDD'99 do oceny swoich rozwiązań używali tego samego zbioru testowego,
co umożliwia porównanie wyników otrzymanych w tej pracy z wynikami z konkursu.

\section{Wyniki eksperymentów}
\label{sec:wyniki}

W tym rozdziale przedstawiono wyniki eksperymentów dla trzech wybranych algorytmów:
k-NN, naiwnego Bayesa oraz SVM. 
Rozwiązaniem referencyjnym będzie rozwiązanie zwycięzcy konkursu KDD'99,
o łącznym błędzie klasyfikacji równym 7.29\%. Macierz pomyłek dla 
tego rozwiązania wygląda następująco:

\begin{table}[H]
\centering
\begin{tabular}{ | l | l | l | l | l | l | l | } \hline
	& normal & probe & dos 	& u2r 	& r2l 	& Poprawnych	\\ \hline
normal 	& 60262 & 243 	& 78	& 4	& 6 	& 99.5\% 	\\ \hline
probe 	& 511 	& 3471 	& 184	& 0	& 0 	& 83.3\% 	\\ \hline
dos 	& 5299 	& 1328 	& 223226& 0 	& 0 	& 97.1\% 	\\ \hline
u2r 	& 168 	& 20 	& 0	& 30	& 10	& 13.2\%	\\ \hline
r2l 	& 14527 & 294 	& 0	& 8	& 1360	& 8.4\%		\\ \hline
\end{tabular} 
\end{table}

Wartość 14527 oznacza, że 14527 przykładów, które faktycznie należały do klasy r2l, zaklasyfikowano
jako normal.

\subsection{k-NN}

Algorytm k-NN w wersji kd-tree został wielokrotnie uruchomiony na pełnym zbiorze trenującym
z różnymi wartościami $k$.
Dla $k=3$ osiągnięto najniższy błąd klasyfikacji na zbiorze testowym równy 7.68\%:

\begin{table}[H]
\centering
\begin{tabular}{ | r | r | r | } \hline
$k$ & Błąd klasyfikacji & Czas w sekundach \\ \hline
1 & 7.76\% & 695 \\ \hline
3 & 7.68\% & 691 \\ \hline
5 & 7.75\% & 706 \\ \hline
7 & 7.76\% & 615 \\ \hline
9 & 7.77\% & 716 \\ \hline
\end{tabular} 
\end{table}

Czas wykonywania algorytmu wynosił od 10 do 12 minut.
Macierz pomyłek dla najlepszego wariantu 3-NN wyglądała następująco:

\begin{table}[H]
\centering
\begin{tabular}{ | l | l | l | l | l | l | l | } \hline
	& normal & probe & dos 	& u2r 	& r2l 	& Poprawnych	\\ \hline
normal 	& 59953 & 518 	& 118	& 0	& 3 	& 98.9\% 	\\ \hline
probe 	& 255 	& 3446 	& 465	& 0	& 0 	& 82.7\% 	\\ \hline
dos 	& 6033 	& 712 	& 223108& 0 	& 0 	& 97\% 		\\ \hline
u2r 	& 214 	& 4 	& 0	& 10	& 0	& 4.4\%		\\ \hline
r2l 	& 15569 & 4 	& 3	& 0	& 613	& 3.8\%		\\ \hline
\end{tabular} 
\end{table}

Otrzymany klasyfikator 3-NN rozpoznaje każdą klasę trochę gorzej niż klasyfikator zwycięzcy
konkursu KDD'99.

\subsection{Naiwny klasyfikator Bayesa}

Naiwny klasyfikator Bayesa na pełnym zbiorze trenującym osiągnął błąd 16.1\% w około 19
minut.
Próbowano również wygładzania Laplace'a z parametrem 0.5, 1, 3 oraz 100, jednak
nie miało to praktycznego wpływu na wyniki klasyfikacji. Macierz pomyłek dla wszystkich
wariantów wyglądała następująco:

\begin{table}[H]
\centering
\begin{tabular}{ | l | l | l | l | l | l | l | } \hline
	& normal & probe & dos 	& u2r 	& r2l 	& Poprawnych	\\ \hline
normal 	& 35930 & 137 	& 15601	& 8777	& 147 	& 59.3\% 	\\ \hline
probe 	& 470 	& 2268 	& 666	& 762	& 0 	& 54.4\% 	\\ \hline
dos 	& 3616 	& 61 	& 222564& 3611 	& 1 	& 96.9\% 	\\ \hline
u2r 	& 8 	& 0 	& 154	& 60	& 6	& 26.3\%	\\ \hline
r2l 	& 188 	& 1 	& 11018	& 4924	& 58	& 0.4\%		\\ \hline
\end{tabular} 
\end{table}

Naiwny klasyfikator Bayesa w porównaniu do rozwiązania zwycięskiego gorzej radzi sobie
niemal ze wszystkimi klasami -- oprócz u2r. Dla klasy u2r naiwny Bayes rozpoznał poprawnie
dwa razy więcej przykładów niż najlepsze rozwiązanie w konkursie KDD'99. 
Ogólnie jednak naiwny Bayes jest znacznie gorszy.

\subsection{SVM}

\subsection{SMOTE}

\end{document}